from __future__ import annotations
import hashlib
import json
from pathlib import Path
from dir2md.core import Config, generate_markdown_report
from dir2md.cli import _resolve_custom_mask_patterns
from dir2md.masking import apply_masking


def _make_repo(tmp: Path) -> Path:
    (tmp/"src").mkdir(parents=True, exist_ok=True)
    # Make this file long enough to trigger truncation
    long_content = "\n".join([f"    print('line {i}')" for i in range(100)])
    (tmp/"src"/"a.py").write_text(f"""
import os

class A: pass

def foo():
{long_content}
    return 42
""", encoding="utf-8")
    (tmp/"src"/"b.py").write_text("""
import sys

def bar():
    return 43
""", encoding="utf-8")
    # Similar file (for deduplication testing)
    (tmp/"src"/"b_copy.py").write_text((tmp/"src"/"b.py").read_text(encoding="utf-8"), encoding="utf-8")
    (tmp/"README.md").write_text("# Title\n\nSome text\n", encoding="utf-8")
    return tmp


def test_budget_and_modes(tmp_path: Path):
    root = _make_repo(tmp_path)
    cfg = Config(
        root=root, output=root/"OUT.md", include_globs=[], exclude_globs=[], omit_globs=[],
        respect_gitignore=False, follow_symlinks=False, max_bytes=200_000, max_lines=2000,
        include_contents=True, only_ext=None, add_stats=True, add_toc=False,
        llm_mode="summary", budget_tokens=200, max_file_tokens=1200, dedup_bits=16,
        sample_head=120, sample_tail=40, strip_comments=False, emit_manifest=True,
        preset="pro", explain_capsule=True,
    )
    md = generate_markdown_report(cfg)
    assert "Estimated tokens (prompt):" in md
    mpath = (root/"OUT.manifest.json")
    assert mpath.exists()
    man = json.loads(mpath.read_text(encoding="utf-8"))
    # b_copy.py likely to be excluded due to deduplication
    paths = {entry["path"] for entry in man["files"]}
    assert any(p.endswith("a.py") for p in paths)
    assert any(p.endswith("b.py") for p in paths)


def test_ref_mode_manifest(tmp_path: Path):
    root = _make_repo(tmp_path)
    cfg = Config(
        root=root, output=root/"OUT.md", include_globs=[], exclude_globs=[], omit_globs=[],
        respect_gitignore=False, follow_symlinks=False, max_bytes=200_000, max_lines=2000,
        include_contents=True, only_ext=None, add_stats=True, add_toc=False,
        llm_mode="ref", budget_tokens=120, max_file_tokens=1200, dedup_bits=16,
        sample_head=120, sample_tail=40, strip_comments=False, emit_manifest=True,
        preset="pro", explain_capsule=False,
    )
    generate_markdown_report(cfg)
    man = json.loads((root/"OUT.manifest.json").read_text(encoding="utf-8"))
    assert "stats" in man
    assert "files" in man
    assert all("sha256" in e for e in man["files"])


def test_inline_sampling(tmp_path: Path):
    root = _make_repo(tmp_path)
    # Drastically reduced budget to trigger sampling
    cfg = Config(
        root=root, output=root/"OUT.md", include_globs=[], exclude_globs=[], omit_globs=[],
        respect_gitignore=False, follow_symlinks=False, max_bytes=200_000, max_lines=50,
        include_contents=True, only_ext=None, add_stats=True, add_toc=False,
        llm_mode="inline", budget_tokens=50, max_file_tokens=30, dedup_bits=0,
        sample_head=5, sample_tail=3, strip_comments=False, emit_manifest=False,
        preset="pro", explain_capsule=True,
    )
    md = generate_markdown_report(cfg)
    assert "truncated middle" in md
    assert "why: inline" in md

def test_masking(tmp_path: Path):
    root = _make_repo(tmp_path)
    # Add a file with a secret
    secret_content = "My AWS key is AKIAIOSFODNN7EXAMPLE"
    (root / ".env").write_text(secret_content, encoding="utf-8")

    # Add a file with a private key
    private_key_content = """-----BEGIN PRIVATE KEY-----
MIIEvQIBADANBgkqhkiG9w0BAQEFAASCBKcwggSjAgEAAoIBAQC7VJTUt9Us8cKB
UmV1F2Cu5CX2jUcZdVRrVNjm/4Sk8DohVhQj4JY=
-----END PRIVATE KEY-----"""
    (root / "private_key.pem").write_text(private_key_content, encoding="utf-8")

    cfg = Config(
        root=root, output=root/"OUT.md", include_globs=[], exclude_globs=[], omit_globs=[],
        respect_gitignore=False, follow_symlinks=False, max_bytes=200_000, max_lines=2000,
        include_contents=True, only_ext=None, add_stats=True, add_toc=False,
        llm_mode="inline", budget_tokens=1000, max_file_tokens=1000, dedup_bits=0,
        sample_head=120, sample_tail=40, strip_comments=False, emit_manifest=False,
        preset="pro", explain_capsule=False, no_timestamp=True,
        masking_mode="basic",
    )
    md = generate_markdown_report(cfg)
    # Check AWS key masking
    assert secret_content not in md
    assert "[*** MASKED_SECRET ***]" in md

    # Check private key masking - entire block should be masked
    assert private_key_content not in md
    assert "-----BEGIN PRIVATE KEY-----" not in md
    assert "MIIEvQIBADANBgkqhkiG9w0BAQEFAASCBKcwggSjAgEAAoIBAQC7VJTUt9Us8cKB" not in md
    assert "-----END PRIVATE KEY-----" not in md

    # Test with masking off
    cfg.masking_mode = "off"
    md_unmasked = generate_markdown_report(cfg)
    assert secret_content in md_unmasked
    assert private_key_content in md_unmasked


def test_custom_mask_patterns(tmp_path: Path):
    root = _make_repo(tmp_path)
    custom_secret = "custom-secret: my-token-123"
    (root / "secrets.txt").write_text(custom_secret, encoding="utf-8")

    cfg = Config(
        root=root,
        output=root / "OUT.md",
        include_globs=[],
        exclude_globs=[],
        omit_globs=[],
        respect_gitignore=False,
        follow_symlinks=False,
        max_bytes=200_000,
        max_lines=2000,
        include_contents=True,
        only_ext=None,
        add_stats=True,
        add_toc=False,
        llm_mode="inline",
        budget_tokens=1000,
        max_file_tokens=1000,
        dedup_bits=0,
        sample_head=120,
        sample_tail=40,
        strip_comments=False,
        emit_manifest=False,
        preset="pro",
        explain_capsule=False,
        no_timestamp=True,
        masking_mode="off",
        custom_mask_patterns=[r"custom-secret:\s+[^\s]+"],
    )
    md = generate_markdown_report(cfg)
    assert custom_secret not in md
    assert "[*** MASKED_SECRET ***]" in md
    # Ensure turning off custom patterns reveals the secret again
    cfg.custom_mask_patterns = []
    md_unmasked = generate_markdown_report(cfg)
    assert custom_secret in md_unmasked
    assert "[*** MASKED_SECRET ***]" not in md_unmasked


def test_custom_mask_patterns_from_file(tmp_path: Path):
    root = _make_repo(tmp_path)
    api_secret = "token=abc123"
    (root / "secrets.ini").write_text(api_secret, encoding="utf-8")

    pattern_file = tmp_path / "patterns.json"
    pattern_file.write_text(json.dumps({"patterns": [r"token=\w+"]}), encoding="utf-8")

    patterns = _resolve_custom_mask_patterns(
        [],
        [pattern_file.resolve().as_uri()],
    )

    cfg = Config(
        root=root,
        output=root / "OUT.md",
        include_globs=[],
        exclude_globs=[],
        omit_globs=[],
        respect_gitignore=False,
        follow_symlinks=False,
        max_bytes=200_000,
        max_lines=2000,
        include_contents=True,
        only_ext=None,
        add_stats=True,
        add_toc=False,
        llm_mode="inline",
        budget_tokens=1000,
        max_file_tokens=1000,
        dedup_bits=0,
        sample_head=120,
        sample_tail=40,
        strip_comments=False,
        emit_manifest=False,
        preset="pro",
        explain_capsule=False,
        no_timestamp=True,
        masking_mode="off",
        custom_mask_patterns=patterns,
    )
    md = generate_markdown_report(cfg)
    assert api_secret not in md
    assert "[*** MASKED_SECRET ***]" in md


def test_custom_mask_invalid_regex_logs_and_continues(capsys):
    aws_key = "AKIAIOSFODNN7EXAMPLE"
    masked = apply_masking(
        f"key={aws_key}",
        mode="basic",
        custom_patterns=["[unclosed"],
    )
    out = capsys.readouterr().out
    assert "Skipping invalid custom mask pattern" in out
    assert aws_key not in masked
    assert "[*** MASKED_SECRET ***]" in masked


def test_custom_mask_priority_before_builtin():
    aws_key = "AKIAIOSFODNN7EXAMPLE"
    text = f"api_secret -> hide-me\nAWS key {aws_key}"
    masked = apply_masking(
        text,
        mode="basic",
        custom_patterns=[r"api_secret\s*->\s*\S+"],
    )
    assert "api_secret" not in masked
    assert "[*** MASKED_SECRET ***]" in masked
    assert aws_key not in masked


def test_masking_pro_license_mode_respect(tmp_path: Path, monkeypatch):
    """Test that masking respects basic vs advanced mode even with Pro license"""
    from dir2md.masking import apply_masking

    # Mock Pro license to be available
    def mock_check_feature(feature_name):
        return feature_name == 'advanced_masking'

    monkeypatch.setattr('dir2md.masking.license_manager.check_feature', mock_check_feature)

    # Test content with both basic and advanced patterns
    github_token = "ghp_1234567890abcdefghijklmnopqrstuvwxyz123"  # Advanced pattern
    aws_key = "AKIAIOSFODNN7EXAMPLE"  # Basic pattern
    test_content = f"GitHub token: {github_token}\nAWS key: {aws_key}"

    # Test basic mode - should only mask basic patterns even with Pro license
    basic_masked = apply_masking(test_content, mode="basic")
    assert aws_key not in basic_masked  # AWS key should be masked (basic pattern)
    assert github_token in basic_masked  # GitHub token should NOT be masked in basic mode
    assert "[*** MASKED_SECRET ***]" in basic_masked

    # Test advanced mode - should mask both basic and advanced patterns
    advanced_masked = apply_masking(test_content, mode="advanced")
    assert aws_key not in advanced_masked  # AWS key should be masked
    assert github_token not in advanced_masked  # GitHub token should be masked in advanced mode
    assert "[*** MASKED_SECRET ***]" in advanced_masked
    assert "[*** MASKED_SECRET_PRO ***]" in advanced_masked

    # Test off mode - should mask nothing
    off_masked = apply_masking(test_content, mode="off")
    assert aws_key in off_masked
    assert github_token in off_masked
    assert "[*** MASKED_SECRET ***]" not in off_masked


def test_include_glob_filtering(tmp_path: Path):
    """Test that --include-glob properly filters files"""
    root = _make_repo(tmp_path)

    # Create files with different extensions
    (root / "main.py").write_text("print('hello')", encoding="utf-8")
    (root / "config.json").write_text('{"key": "value"}', encoding="utf-8")
    (root / "readme.md").write_text("# Project", encoding="utf-8")
    (root / "script.js").write_text("console.log('test')", encoding="utf-8")

    # Test with include glob for Python files only
    cfg = Config(
        root=root, output=root/"OUT.md", include_globs=["*.py"], exclude_globs=[], omit_globs=[],
        respect_gitignore=False, follow_symlinks=False, max_bytes=200_000, max_lines=2000,
        include_contents=True, only_ext=None, add_stats=True, add_toc=False,
        llm_mode="inline", budget_tokens=1000, max_file_tokens=1000, dedup_bits=0,
        sample_head=120, sample_tail=40, strip_comments=False, emit_manifest=False,
        preset="raw", explain_capsule=False, no_timestamp=True,
        masking_mode="off",
    )

    # Should include main.py content but not other files' content
    md = generate_markdown_report(cfg)
    assert "main.py" in md  # File should appear in tree
    assert "print('hello')" in md  # Content should be included

    # Other files may appear in tree but their content should not be included
    assert '{"key": "value"}' not in md  # JSON content should not be included
    assert "console.log('test')" not in md  # JS content should not be included

    # Verify that config.json appears in tree but not in file contents section
    if "## File Contents" in md:
        file_contents_section = md.split("## File Contents")[1]
        assert "main.py" in file_contents_section
        assert "config.json" not in file_contents_section

    # Test with multiple include patterns
    cfg.include_globs = ["*.py", "*.json"]
    md_multi = generate_markdown_report(cfg)

    # Should include both .py and .json files' content
    assert "main.py" in md_multi
    assert "print('hello')" in md_multi
    assert '{"key": "value"}' in md_multi  # JSON content should now be included
    assert "console.log('test')" not in md_multi  # JS content should not be included


def test_follow_symlinks_behavior(tmp_path: Path):
    """Test that --follow-symlinks controls symlink traversal"""
    root = _make_repo(tmp_path)

    # Create a regular directory and file
    regular_dir = root / "regular_dir"
    regular_dir.mkdir()
    (regular_dir / "regular_file.txt").write_text("regular content", encoding="utf-8")

    # Create a symlinked directory (if the OS supports it)
    try:
        symlink_dir = root / "symlink_dir"
        symlink_dir.symlink_to(regular_dir)
        symlinks_supported = True
    except (OSError, NotImplementedError):
        # Skip symlink tests on systems that don't support them
        symlinks_supported = False

    if not symlinks_supported:
        import pytest
        pytest.skip("Symlinks not supported on this system")

    # Test with follow_symlinks=False (default)
    cfg = Config(
        root=root, output=root/"OUT.md", include_globs=[], exclude_globs=[], omit_globs=[],
        respect_gitignore=False, follow_symlinks=False, max_bytes=200_000, max_lines=2000,
        include_contents=True, only_ext=None, add_stats=True, add_toc=False,
        llm_mode="inline", budget_tokens=1000, max_file_tokens=1000, dedup_bits=0,
        sample_head=120, sample_tail=40, strip_comments=False, emit_manifest=False,
        preset="raw", explain_capsule=False, no_timestamp=True,
        masking_mode="off",
    )
    md_no_symlinks = generate_markdown_report(cfg)

    # Should show symlink in tree but not traverse into it
    assert "symlink_dir" in md_no_symlinks  # Listed in tree
    assert "regular_dir" in md_no_symlinks  # Regular dir should be traversed
    assert "regular_file.txt" in md_no_symlinks  # File in regular dir
    assert md_no_symlinks.count("regular content") == 1  # Should appear only once

    # Test with follow_symlinks=True
    cfg.follow_symlinks = True
    md_with_symlinks = generate_markdown_report(cfg)

    # Should traverse symlinked directory
    assert "symlink_dir" in md_with_symlinks
    assert "regular_dir" in md_with_symlinks
    assert "regular_file.txt" in md_with_symlinks
    # Content might appear twice if symlink is followed (once from regular_dir, once from symlink_dir)
    # But deduplication might prevent this, so we just check it appears at least once
    assert "regular content" in md_with_symlinks


def test_sha256_preservation_with_max_bytes(tmp_path: Path):
    """Test that SHA-256 hash reflects full file even when max_bytes truncates content"""
    root = _make_repo(tmp_path)

    # Create a large file that will exceed max_bytes
    large_content = "This is a test file with lots of content. " * 100  # ~4300 bytes
    large_file = root / "large_file.txt"
    large_file.write_text(large_content, encoding="utf-8")

    # Calculate expected SHA-256 of full content
    
    # Test the candidates list directly to verify SHA-256 preservation
    # We'll use a simple approach to access the candidates data structure
    cfg = Config(
        root=root, output=root/"OUT.md", include_globs=[], exclude_globs=[], omit_globs=[],
        respect_gitignore=False, follow_symlinks=False, max_bytes=1000, max_lines=2000,  # Truncate to 1KB
        include_contents=True, only_ext=None, add_stats=False, add_toc=False,
        llm_mode="inline", budget_tokens=5000, max_file_tokens=1000, dedup_bits=0,
        sample_head=120, sample_tail=40, strip_comments=False, emit_manifest=False,
        preset="raw", explain_capsule=False, no_timestamp=True,
        masking_mode="off",
    )

    # Generate report and check that truncation occurred but SHA-256 is correct
    md = generate_markdown_report(cfg)

    # Verify content was truncated (should not contain the full repeated content)
    assert len(large_content) > 1000  # Original is larger than max_bytes
    
    # The full content should not appear, but the beginning should
    content_lines = large_content.split('\n')[0]  # Get first line of repeated content
    assert content_lines[:50] in md  # Beginning should be present

    # For now, we'll verify the fix worked by ensuring we don't get an error
    # The real verification would need access to the internal candidates structure
    # but our fix ensures SHA-256 is calculated before truncation

    # Test passes if no exceptions are raised and basic content checks pass
    assert "large_file.txt" in md
    assert "This is a test file with lots of content" in md  # Beginning should be there


def test_nested_glob_patterns(tmp_path: Path):
    """Glob patterns should match nested files using gitwildmatch semantics."""
    root = tmp_path / "test_project"
    root.mkdir()

    (root / "src" / "utils").mkdir(parents=True, exist_ok=True)
    (root / "tests" / "unit").mkdir(parents=True, exist_ok=True)
    (root / "__pycache__").mkdir(parents=True, exist_ok=True)
    (root / "src" / "__pycache__").mkdir(parents=True, exist_ok=True)

    (root / "main.py").write_text("print('main')", encoding="utf-8")
    (root / "config.json").write_text('{"root": "config"}', encoding="utf-8")
    (root / "src" / "utils" / "helper.py").write_text("def helper(): pass", encoding="utf-8")
    (root / "src" / "utils" / "data.json").write_text('{"key": "value"}', encoding="utf-8")
    (root / "tests" / "unit" / "test_helper.py").write_text("def test_helper(): pass", encoding="utf-8")
    (root / "__pycache__" / "helper.cpython-39.pyc").write_bytes(b"compiled_bytecode")
    (root / "src" / "__pycache__" / "main.cpython-39.pyc").write_bytes(b"more_bytecode")

    def run_config(include: list[str] | None = None, exclude: list[str] | None = None, omit: list[str] | None = None, suffix: str = "out") -> set[str]:
        cfg = Config(
            root=root,
            output=root / f"{suffix}.md",
            include_globs=include or [],
            exclude_globs=exclude or [],
            omit_globs=omit or [],
            respect_gitignore=False,
            follow_symlinks=False,
            max_bytes=200_000,
            max_lines=2000,
            include_contents=True,
            only_ext=None,
            add_stats=True,
            add_toc=False,
            llm_mode="ref",
            budget_tokens=10_000,
            max_file_tokens=2_000,
            dedup_bits=0,
            sample_head=120,
            sample_tail=40,
            strip_comments=False,
            emit_manifest=True,
            preset="pro",
            explain_capsule=False,
            no_timestamp=True,
            masking_mode="off",
        )
        generate_markdown_report(cfg)
        manifest_path = cfg.output.with_suffix('.manifest.json')
        assert manifest_path.exists(), "Manifest should be generated"
        manifest = json.loads(manifest_path.read_text(encoding="utf-8"))
        normalized: set[str] = set()
        for entry in manifest["files"]:
            raw_path = entry.get("path", "")
            if not raw_path:
                continue
            candidate = Path(raw_path)
            if candidate.is_absolute():
                try:
                    candidate = candidate.relative_to(root)
                except ValueError:
                    pass
            normalized.add(str(candidate).replace('\\', '/'))
        return normalized

    include_py = run_config(include=["**/*.py"], suffix="include_py")
    assert include_py == {"src/utils/helper.py", "tests/unit/test_helper.py"}
    assert "main.py" not in include_py

    include_star_py = run_config(include=["*.py"], suffix="include_star")
    assert {"main.py", "src/utils/helper.py", "tests/unit/test_helper.py"}.issubset(include_star_py)

    include_src = run_config(include=["src/**/*.py"], suffix="include_src")
    assert include_src == {"src/utils/helper.py"}

    include_recursive_root = run_config(include=["**/main.py"], suffix="include_recursive_root")
    assert include_recursive_root == {"main.py"}

    exclude_pyc = run_config(exclude=["**/*.pyc"], suffix="exclude_pyc")
    assert "__pycache__/helper.cpython-39.pyc" not in exclude_pyc
    assert "src/__pycache__/main.cpython-39.pyc" not in exclude_pyc
    assert "main.py" in exclude_pyc

    omit_tests = run_config(omit=["tests/**"], suffix="omit_tests")
    assert "tests/unit/test_helper.py" not in omit_tests
    assert "src/utils/helper.py" in omit_tests


def test_symlink_outside_root_skipped(tmp_path: Path):
    """Symlinks that escape the root should not be followed even when follow_symlinks=True."""
    root = tmp_path / "root"
    root.mkdir()
    outside = tmp_path / "outside"
    outside.mkdir()
    target = outside / "secret.txt"
    target.write_text("outside-secret", encoding="utf-8")
    link = root / "link_to_outside.txt"
    try:
        link.symlink_to(target)
    except (OSError, NotImplementedError):
        import pytest
        pytest.skip("Symlinks not supported on this system")

    cfg = Config(
        root=root,
        output=root / "OUT.md",
        include_globs=[],
        exclude_globs=[],
        omit_globs=[],
        respect_gitignore=False,
        follow_symlinks=True,
        max_bytes=200_000,
        max_lines=2000,
        include_contents=True,
        only_ext=None,
        add_stats=True,
        add_toc=False,
        llm_mode="inline",
        budget_tokens=1000,
        max_file_tokens=1000,
        dedup_bits=0,
        sample_head=120,
        sample_tail=40,
        strip_comments=False,
        emit_manifest=True,
        preset="pro",
        explain_capsule=False,
        masking_mode="off",
        no_timestamp=True,
        custom_mask_patterns=[],
    )
    md = generate_markdown_report(cfg)
    manifest = json.loads((root / "OUT.manifest.json").read_text(encoding="utf-8"))
    paths = {entry["path"] for entry in manifest["files"]}
    assert "link_to_outside.txt" not in paths
    assert "outside-secret" not in md


def test_streaming_respects_max_bytes_and_full_hash(tmp_path: Path):
    """Large files should use full-hash with truncated content to respect max_bytes."""
    root = tmp_path / "root"
    root.mkdir()
    content = "start-" + ("X" * 10000) + "-end"
    target = root / "huge.txt"
    target.write_text(content, encoding="utf-8")
    expected_hash = hashlib.sha256(content.encode("utf-8")).hexdigest()

    cfg = Config(
        root=root,
        output=root / "OUT.md",
        include_globs=[],
        exclude_globs=[],
        omit_globs=[],
        respect_gitignore=False,
        follow_symlinks=False,
        max_bytes=100,
        max_lines=2000,
        include_contents=True,
        only_ext=None,
        add_stats=True,
        add_toc=False,
        llm_mode="inline",
        budget_tokens=1000,
        max_file_tokens=200,
        dedup_bits=0,
        sample_head=120,
        sample_tail=40,
        strip_comments=False,
        emit_manifest=True,
        preset="pro",
        explain_capsule=False,
        masking_mode="off",
        no_timestamp=True,
        custom_mask_patterns=[],
    )
    md = generate_markdown_report(cfg)
    manifest = json.loads((root / "OUT.manifest.json").read_text(encoding="utf-8"))
    entry = next(e for e in manifest["files"] if e["path"] == "huge.txt")
    assert entry["sha256"] == expected_hash
    assert "start-" in md
    assert "-end" not in md


def test_query_filters_matches_and_snippet(tmp_path: Path):
    """Query should prioritize matching files and include snippets in output."""
    root = tmp_path
    (root / "match.txt").write_text("alpha beta query gamma delta", encoding="utf-8")
    (root / "other.txt").write_text("unrelated content", encoding="utf-8")

    cfg = Config(
        root=root,
        output=root / "OUT.md",
        include_globs=[],
        exclude_globs=[],
        omit_globs=[],
        respect_gitignore=False,
        follow_symlinks=False,
        max_bytes=200_000,
        max_lines=2000,
        include_contents=True,
        only_ext=None,
        add_stats=True,
        add_toc=False,
        llm_mode="inline",
        budget_tokens=1000,
        max_file_tokens=400,
        dedup_bits=0,
        sample_head=120,
        sample_tail=40,
        strip_comments=False,
        emit_manifest=True,
        preset="pro",
        explain_capsule=False,
        masking_mode="off",
        no_timestamp=True,
        custom_mask_patterns=[],
        query="beta query",
    )
    md = generate_markdown_report(cfg)
    manifest = json.loads((root / "OUT.manifest.json").read_text(encoding="utf-8"))
    paths = {entry["path"] for entry in manifest["files"]}
    assert paths == {"match.txt"}
    assert "<!-- query:" in md
    assert "alpha beta query gamma delta" in md


def test_output_format_jsonl(tmp_path: Path):
    """JSONL output should emit one entry per selected file with query metadata."""
    root = tmp_path
    (root / "note.md").write_text("This is a note about rockets.", encoding="utf-8")

    cfg = Config(
        root=root,
        output=root / "OUT.jsonl",
        include_globs=[],
        exclude_globs=[],
        omit_globs=[],
        respect_gitignore=False,
        follow_symlinks=False,
        max_bytes=200_000,
        max_lines=2000,
        include_contents=True,
        only_ext=None,
        add_stats=True,
        add_toc=False,
        llm_mode="summary",
        budget_tokens=1000,
        max_file_tokens=400,
        dedup_bits=0,
        sample_head=120,
        sample_tail=40,
        strip_comments=False,
        emit_manifest=True,
        preset="pro",
        explain_capsule=False,
        masking_mode="off",
        no_timestamp=True,
        custom_mask_patterns=[],
        query="rockets",
        output_format="jsonl",
    )

    out = generate_markdown_report(cfg)
    lines = [json.loads(line) for line in out.splitlines() if line.strip()]
    assert len(lines) == 1
    entry = lines[0]
    assert entry["path"] == "note.md"
    assert entry["mode"] == "summary"
    assert entry["lang"] == "markdown"
    assert entry["match_score"] >= 1
    assert "rockets" in entry["content"]


